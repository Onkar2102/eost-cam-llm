models:
  llama:
    provider: huggingface
    name: meta-llama/Llama-3.2-3B-instruct
    strategy: local
    task_type: text-generation
    max_batch_size: 4
    generation_args:
      do_sample: true
      temperature: 1.0
      top_k: 50
      top_p: 1.0
      num_return_sequences: 1

  openai:
    provider: openai
    name: gpt-4.1
    strategy: api
    task_type: chat-completion
    api_base: https://api.openai.com/v1
    generation_args:
      max_tokens: 32768
      temperature: 1.0
      top_p: 1.0
      frequency_penalty: 0
      presence_penalty: 0

  mistral:
    provider: huggingface
    name: mistralai/Ministral-8B-Instruct-2410
    strategy: local
    task_type: text-generation
    max_batch_size: 4
    generation_args:
      max_tokens: 128000
      do_sample: true
      temperature: 0.9
      top_k: 40
      top_p: 0.95
      num_return_sequences: 1